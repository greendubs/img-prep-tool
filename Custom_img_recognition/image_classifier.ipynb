{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os as os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“data” is the array of all images converted to numpy array and “labels” is the array of corresponding labels.\n",
    "\n",
    "#### How it works —\n",
    "\n",
    "We go into each directory and go through all the files inside it. Then we read the images using cv2.imread. After that using Image object from PIL we convert the image into array. Since while training the convolutional neural network it is required that you have images of same size we resize the images to width and height of 50px. Then we convert it to numpy array just by passing the image array in the function np.array() and we append the numpy array in our data array. Also add corresponding label to the image. Eg for cat label is 0, for dog label is 1 and so on. Labels are required as the training is done in supervised manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "dogs=os.listdir(\"./raw-img/cane\")\n",
    "for dog in dogs:\n",
    "    imag=cv2.imread(\"./raw-img/cane/\"+dog)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(0)\n",
    "\n",
    "horses=os.listdir(\"./raw-img/cavallo\")\n",
    "for horse in horses:\n",
    "    imag=cv2.imread(\"./raw-img/cavallo/\"+horse)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(1)\n",
    "\n",
    "sheeps=os.listdir(\"./raw-img/pecora\")\n",
    "for sheep in sheeps:\n",
    "    imag=cv2.imread(\"./raw-img/pecora/\"+sheep)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(2)\n",
    "    \n",
    "\n",
    "chipmunks=os.listdir(\"./raw-img/scoiattolo\")\n",
    "for chipmunk in chipmunks:\n",
    "    imag=cv2.imread(\"./raw-img/scoiattolo/\"+chipmunk)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the “data” and “labels” are normal array , convert them to numpy arrays-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save these numpy arrays so that you dont need to do this image manipulation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"animals\",animals)\n",
    "np.save(\"labels\",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the arrays ( Optional : Required only if you have closed your jupyter notebook after saving numpy array )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals=np.load(\"animals.npy\")\n",
    "labels=np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now shuffle the “animals” and “labels” set so that you get good mixture when you separate the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(animals.shape[0])\n",
    "np.random.shuffle(s)\n",
    "animals=animals[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a variable num_classes which is the total number of animal categories and a variable data_length which is size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(labels))\n",
    "data_length=len(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide data into test and train\n",
    "Take 90% of data in train set and 10% in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,x_test)=animals[(int)(0.1*data_length):],animals[:(int)(0.1*data_length)]\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_length=len(x_train)\n",
    "test_length=len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide labels into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make labels into One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "#One hot encoding\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation part is over. All you have to do is think about hyper parameters like Filter size, number of filters, which type of padding to use, which activatioon functions to use etc.\n",
    "\n",
    "I added 3 pairs of Conv2D layer and Maxpool2D layer with increasing filter sizes ( 16,32 ,64) . This helps to make image grow more in depthwise and become more flatten. Maxpool layers are great as they optimize the training time. I have also add Dropout layers to reduce overfitting.\n",
    "In final Dense layer there are 20 nodes because we have 20 categories of animals (cat,dog,bird,fish). Softmax activation is used to give scores to these categories which lie between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2004      \n",
      "=================================================================\n",
      "Total params: 1,165,048\n",
      "Trainable params: 1,165,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import sequential model and all the required layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "#make model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10052/10052 [==============================] - 8s 838us/step - loss: 1.0812 - accuracy: 0.5414\n",
      "Epoch 2/100\n",
      "10052/10052 [==============================] - 9s 869us/step - loss: 0.8933 - accuracy: 0.6324\n",
      "Epoch 3/100\n",
      "10052/10052 [==============================] - 9s 860us/step - loss: 0.8119 - accuracy: 0.6735\n",
      "Epoch 4/100\n",
      "10052/10052 [==============================] - 9s 868us/step - loss: 0.7362 - accuracy: 0.7146\n",
      "Epoch 5/100\n",
      "10052/10052 [==============================] - 8s 825us/step - loss: 0.6676 - accuracy: 0.7374\n",
      "Epoch 6/100\n",
      "10052/10052 [==============================] - 9s 861us/step - loss: 0.6142 - accuracy: 0.7698\n",
      "Epoch 7/100\n",
      "10052/10052 [==============================] - 9s 866us/step - loss: 0.5558 - accuracy: 0.78520s - loss: 0.5568 - accura\n",
      "Epoch 8/100\n",
      "10052/10052 [==============================] - 10s 970us/step - loss: 0.5231 - accuracy: 0.8003\n",
      "Epoch 9/100\n",
      "10052/10052 [==============================] - 10s 956us/step - loss: 0.4634 - accuracy: 0.8283\n",
      "Epoch 10/100\n",
      "10052/10052 [==============================] - 8s 840us/step - loss: 0.4321 - accuracy: 0.8394\n",
      "Epoch 11/100\n",
      "10052/10052 [==============================] - 8s 818us/step - loss: 0.4017 - accuracy: 0.8465\n",
      "Epoch 12/100\n",
      "10052/10052 [==============================] - 8s 824us/step - loss: 0.3215 - accuracy: 0.8796\n",
      "Epoch 13/100\n",
      "10052/10052 [==============================] - 8s 830us/step - loss: 0.2968 - accuracy: 0.8890\n",
      "Epoch 14/100\n",
      "10052/10052 [==============================] - 8s 833us/step - loss: 0.2848 - accuracy: 0.8962\n",
      "Epoch 15/100\n",
      "10052/10052 [==============================] - 8s 823us/step - loss: 0.2194 - accuracy: 0.9210\n",
      "Epoch 16/100\n",
      "10052/10052 [==============================] - 8s 811us/step - loss: 0.2240 - accuracy: 0.9212\n",
      "Epoch 17/100\n",
      "10052/10052 [==============================] - 8s 813us/step - loss: 0.1626 - accuracy: 0.9419\n",
      "Epoch 18/100\n",
      "10052/10052 [==============================] - 8s 798us/step - loss: 0.1414 - accuracy: 0.9521\n",
      "Epoch 19/100\n",
      "10052/10052 [==============================] - 9s 882us/step - loss: 0.1184 - accuracy: 0.9608\n",
      "Epoch 20/100\n",
      "10052/10052 [==============================] - 9s 883us/step - loss: 0.1093 - accuracy: 0.9634\n",
      "Epoch 21/100\n",
      "10052/10052 [==============================] - 9s 860us/step - loss: 0.0987 - accuracy: 0.96780s - loss: 0.0978 - accuracy\n",
      "Epoch 22/100\n",
      "10052/10052 [==============================] - 8s 825us/step - loss: 0.0901 - accuracy: 0.9712\n",
      "Epoch 23/100\n",
      "10052/10052 [==============================] - 9s 860us/step - loss: 0.0742 - accuracy: 0.9753\n",
      "Epoch 24/100\n",
      "10052/10052 [==============================] - 9s 930us/step - loss: 0.0726 - accuracy: 0.9785\n",
      "Epoch 25/100\n",
      "10052/10052 [==============================] - 9s 892us/step - loss: 0.0718 - accuracy: 0.9762\n",
      "Epoch 26/100\n",
      "10052/10052 [==============================] - 9s 901us/step - loss: 0.0766 - accuracy: 0.9746\n",
      "Epoch 27/100\n",
      "10052/10052 [==============================] - 8s 822us/step - loss: 0.0614 - accuracy: 0.9790\n",
      "Epoch 28/100\n",
      "10052/10052 [==============================] - 8s 760us/step - loss: 0.0605 - accuracy: 0.9812\n",
      "Epoch 29/100\n",
      "10052/10052 [==============================] - 9s 848us/step - loss: 0.0562 - accuracy: 0.9823\n",
      "Epoch 30/100\n",
      "10052/10052 [==============================] - 9s 854us/step - loss: 0.0679 - accuracy: 0.9786\n",
      "Epoch 31/100\n",
      "10052/10052 [==============================] - 9s 895us/step - loss: 0.0429 - accuracy: 0.9869\n",
      "Epoch 32/100\n",
      "10052/10052 [==============================] - 8s 843us/step - loss: 0.1028 - accuracy: 0.9666\n",
      "Epoch 33/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0477 - accuracy: 0.9851\n",
      "Epoch 34/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0398 - accuracy: 0.9886\n",
      "Epoch 35/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0408 - accuracy: 0.9861\n",
      "Epoch 36/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0367 - accuracy: 0.9885 0s - loss: 0.0356 - accura\n",
      "Epoch 37/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0388 - accuracy: 0.9876\n",
      "Epoch 38/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0371 - accuracy: 0.9879\n",
      "Epoch 39/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0395 - accuracy: 0.9867 0s - loss: 0.0398 - accuracy: \n",
      "Epoch 40/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0374 - accuracy: 0.9881\n",
      "Epoch 41/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0441 - accuracy: 0.9842\n",
      "Epoch 42/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0434 - accuracy: 0.9847\n",
      "Epoch 43/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0333 - accuracy: 0.9883\n",
      "Epoch 44/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0349 - accuracy: 0.9884\n",
      "Epoch 45/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0312 - accuracy: 0.9908\n",
      "Epoch 46/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0382 - accuracy: 0.9866\n",
      "Epoch 47/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0359 - accuracy: 0.9867\n",
      "Epoch 48/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0280 - accuracy: 0.9912 0s - loss: 0\n",
      "Epoch 49/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0332 - accuracy: 0.9889\n",
      "Epoch 50/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0548 - accuracy: 0.9811\n",
      "Epoch 51/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0324 - accuracy: 0.9893\n",
      "Epoch 52/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0228 - accuracy: 0.9929\n",
      "Epoch 54/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 55/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0350 - accuracy: 0.9877 1s\n",
      "Epoch 56/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0292 - accuracy: 0.9905\n",
      "Epoch 57/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 58/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0299 - accuracy: 0.9904 2s - ETA: 1s - loss: 0.0296 - accu - ETA: \n",
      "Epoch 59/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0267 - accuracy: 0.9907\n",
      "Epoch 60/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0296 - accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0250 - accuracy: 0.9911\n",
      "Epoch 62/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 63/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 64/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0306 - accuracy: 0.9887\n",
      "Epoch 65/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0291 - accuracy: 0.9904\n",
      "Epoch 66/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 67/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0286 - accuracy: 0.9903 0s - loss: 0.029\n",
      "Epoch 68/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0332 - accuracy: 0.9900\n",
      "Epoch 69/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0318 - accuracy: 0.9887\n",
      "Epoch 70/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0252 - accuracy: 0.9908\n",
      "Epoch 71/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0193 - accuracy: 0.9934\n",
      "Epoch 72/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0183 - accuracy: 0.9943\n",
      "Epoch 73/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0214 - accuracy: 0.9923\n",
      "Epoch 74/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0263 - accuracy: 0.9907\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0314 - accuracy: 0.9904\n",
      "Epoch 76/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 77/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0232 - accuracy: 0.9918\n",
      "Epoch 78/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0233 - accuracy: 0.9923\n",
      "Epoch 79/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0276 - accuracy: 0.9904\n",
      "Epoch 80/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0173 - accuracy: 0.9940\n",
      "Epoch 81/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0201 - accuracy: 0.9940\n",
      "Epoch 82/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 83/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0480 - accuracy: 0.9855\n",
      "Epoch 84/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0162 - accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0124 - accuracy: 0.9965\n",
      "Epoch 86/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0237 - accuracy: 0.9922\n",
      "Epoch 87/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0171 - accuracy: 0.9939\n",
      "Epoch 88/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0232 - accuracy: 0.9925\n",
      "Epoch 89/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0215 - accuracy: 0.9930\n",
      "Epoch 90/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0274 - accuracy: 0.9912\n",
      "Epoch 91/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0266 - accuracy: 0.9915 0s - loss: 0.0269 - \n",
      "Epoch 92/100\n",
      "10052/10052 [==============================] - 14s 1ms/step - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 93/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0148 - accuracy: 0.9942\n",
      "Epoch 94/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 95/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.1163 - accuracy: 0.9705\n",
      "Epoch 96/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 97/100\n",
      "10052/10052 [==============================] - 12s 1ms/step - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 98/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0107 - accuracy: 0.9961 0s\n",
      "Epoch 99/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 100/100\n",
      "10052/10052 [==============================] - 13s 1ms/step - loss: 0.0071 - accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22599fe4548>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=50\n",
    "          ,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1s 466us/step\n",
      "\n",
      " Test accuracy: 0.7983871102333069\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single image test\n",
    "def convert_to_array(img):\n",
    "    im = cv2.imread(img)\n",
    "    img = Image.fromarray(im, 'RGB')\n",
    "    image = img.resize((50, 50))\n",
    "    return np.array(image)\n",
    "def get_animal_name(label):\n",
    "    if label==0:\n",
    "        return \"dog\"\n",
    "    if label==1:\n",
    "        return \"horse\"\n",
    "    if label==2:\n",
    "        return \"sheep\"\n",
    "    if label==3:\n",
    "        return \"chipmunk\"\n",
    "def predict_animal(file):\n",
    "    print(\"Predicting .................................\")\n",
    "    ar=convert_to_array(file)\n",
    "    ar=ar/255\n",
    "    label=1\n",
    "    a=[]\n",
    "    a.append(ar)\n",
    "    a=np.array(a)\n",
    "    score=model.predict(a,verbose=1)\n",
    "    print(score)\n",
    "    label_index=np.argmax(score)\n",
    "    print(label_index)\n",
    "    acc=np.max(score)\n",
    "    animal=get_animal_name(label_index)\n",
    "    print(animal)\n",
    "    print(\"The predicted Animal is a \"+animal+\" with accuracy =    \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting .................................\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[3.769014e-21 9.773268e-24 7.239758e-22 1.000000e+00]]\n",
      "3\n",
      "chipmunk\n",
      "The predicted Animal is a chipmunk with accuracy =    1.0\n"
     ]
    }
   ],
   "source": [
    "predict_animal(\"download.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='download.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
